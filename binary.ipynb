{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, os\n",
    "import cv2\n",
    "import shutil\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Major project/dataset/train.csv\")\n",
    "\n",
    "diagnosis_binary = {\n",
    "        0: 'No_DR',\n",
    "        1: 'DR',\n",
    "        2: 'DR',\n",
    "        3: 'DR',\n",
    "        4: 'DR'}\n",
    "\n",
    "df[\"binary\"] = df[\"diagnosis\"].map(diagnosis_binary.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['binary'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from imutils import paths\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3662, 224, 224, 3)\n",
      "(3662, 1)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "width,height=224,224\n",
    "\n",
    "imagePaths = list(paths.list_images('data\\gaussian_filtered_images\\gaussian_filtered_images'))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]   \n",
    "    image = load_img(imagePath, target_size=(width, height))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "data, labels = shuffle(data, labels)\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (2929, 224, 224, 3)\n",
      "Test images: (733, 224, 224, 3)\n",
      "Train label: (2929, 1)\n",
      "Test label: (733, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=.2)\n",
    "\n",
    "print(\"Train images:\",x_train.shape)\n",
    "print(\"Test images:\",x_test.shape)\n",
    "print(\"Train label:\",y_train.shape)\n",
    "print(\"Test label:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (2343, 224, 224, 3)\n",
      "Test images: (586, 224, 224, 3)\n",
      "Train label: (2343, 1)\n",
      "Test label: (586, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "print(\"Train images:\",x_train.shape)\n",
    "print(\"Test images:\",x_val.shape)\n",
    "print(\"Train label:\",y_train.shape)\n",
    "print(\"Test label:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vgg16 = VGG16(include_top=False, input_shape= (224,224,3)) \n",
    "\n",
    "Vgg16.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Vgg16)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64 , activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32 , activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2 , activation=\"sigmoid\"))\n",
    "\n",
    "model.compile( optimizer=\"adam\" , loss=\"binary_crossentropy\" , metrics=\"binary_accuracy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1605696   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,322,530\n",
      "Trainable params: 1,607,842\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_binary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m , patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m , restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\AMRUTH~1\\AppData\\Local\\Temp\\__autograph_generated_file62_yun_e.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Amrutha A\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_binary_accuracy' , patience=10 , restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(x_train , y_train , epochs=100 , batch_size=32,\n",
    "                    validation_data=(x_val,y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('binary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('binary.h5')\n",
    "\n",
    "# Now you can use the loaded model for prediction or further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history):\n",
    "\n",
    "  loss = history.history[\"loss\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "  accuracy = history.history[\"binary_accuracy\"]\n",
    "  val_accuracy = history.history[\"val_binary_accuracy\"]\n",
    "\n",
    "  epochs = range(len(history.history[\"loss\"]))\n",
    "\n",
    "  #plot loss\n",
    "  plt.plot(epochs, loss, label = \"training_loss\")\n",
    "  plt.plot(epochs, val_loss, label = \"val_loss\")\n",
    "  plt.title(\"loss\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()\n",
    "\n",
    "  #plot accuracy\n",
    "  plt.figure() \n",
    "  plt.plot(epochs, accuracy, label = \"training_accuracy\")\n",
    "  plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n",
    "  plt.title(\"accuracy\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "predictions=[\"Mild\",\"Moderate\",\"Proliferate_DR\",\"Severe\"] \n",
    "\n",
    "img = x_test[index]\n",
    "RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "RGBImg= cv2.resize(RGBImg,(224,224))\n",
    "\n",
    "plt.imshow(RGBImg)\n",
    "print(y_test[index]) # true\n",
    "print(f\"Prediction: {predictions[pred[index]]}\") # predicted  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def predict_new(path):\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    RGBImg= cv2.resize(RGBImg,(224,224))\n",
    "    plt.imshow(RGBImg)\n",
    "    image = np.array(RGBImg) / 255.0\n",
    "\n",
    "    predict=model.predict(np.array([image]))\n",
    "    pred=np.argmax(predict,axis=1)\n",
    "    \n",
    "    print(f\"Predicted: {predictions[pred[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_new(\"D:/Major project/dataset/test/severe1.png\")\n",
    "#True --> Mild"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
